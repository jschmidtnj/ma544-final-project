{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suitable-syria",
   "metadata": {},
   "source": [
    "To download the dataset follow the instructions here:\n",
    "- https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data?select=members.csv.7z\n",
    "\n",
    "If you are running archlinux:\n",
    "- git clone https://aur.archlinux.org/kaggle-api.git\n",
    "- cd kaggle-api\n",
    "- makepkg -si\n",
    "- Go to the first link and create a kaggle account and agree to the competition rules\n",
    "- go to your account page on kaggle and create an api key and save the kaggle.json file in the folder ~/.kaggle/\n",
    "- kaggle competitions download -c kkbox-music-recommendation-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "chubby-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tfd\n",
    "\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List, Any, Tuple, Optional, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "democratic-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath: str = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "absent-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory: str, extension: str) -> List[str]:\n",
    "    all_files = os.listdir(directory)\n",
    "    return [os.path.join(directory, file) for file in all_files if file.split('.')[-1] == extension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "shaped-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from disk: 100%|##########| 6/6 [00:19<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "datasets: Dict[str, pd.DataFrame] = dict()\n",
    "for filepath in tqdm(list_files(datapath, 'csv'), ascii=True, desc=\"Loading data from disk\"):\n",
    "    datasets[os.path.basename(filepath).split('.')[0]] = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "varying-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 csv files\n",
      "length of dataset sample_submission is 2556790\n",
      "length of dataset members is 34403\n",
      "length of dataset test is 2556790\n",
      "length of dataset train is 7377418\n",
      "length of dataset songs is 2296320\n",
      "length of dataset song_extra_info is 2295971\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(datasets)} csv files\")\n",
    "for key, value in datasets.items():\n",
    "    print(f\"length of dataset {key} is {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "chicken-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the 'sample_submission' dataset\n",
    "_ = datasets.pop('sample_submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "private-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information for dataset: members\n",
      "Description\n",
      "               city            bd  registered_via  registration_init_time  \\\n",
      "count  34403.000000  34403.000000    34403.000000            3.440300e+04   \n",
      "mean       5.371276     12.280935        5.953376            2.013994e+07   \n",
      "std        6.243929     18.170251        2.287534            2.954015e+04   \n",
      "min        1.000000    -43.000000        3.000000            2.004033e+07   \n",
      "25%        1.000000      0.000000        4.000000            2.012103e+07   \n",
      "50%        1.000000      0.000000        7.000000            2.015090e+07   \n",
      "75%       10.000000     25.000000        9.000000            2.016110e+07   \n",
      "max       22.000000   1051.000000       16.000000            2.017023e+07   \n",
      "\n",
      "       expiration_date  \n",
      "count     3.440300e+04  \n",
      "mean      2.016901e+07  \n",
      "std       7.320925e+03  \n",
      "min       1.970010e+07  \n",
      "25%       2.017020e+07  \n",
      "50%       2.017091e+07  \n",
      "75%       2.017093e+07  \n",
      "max       2.020102e+07  \n",
      "\n",
      "\n",
      "dataframe 'head'\n",
      "                                           msno  city  bd gender  \\\n",
      "0  XQxgAYj3klVKjR3oxPPXYYFp4soD4TuBghkhMTD4oTw=     1   0    NaN   \n",
      "1  UizsfmJb9mV54qE9hCYyU07Va97c0lCRLEQX3ae+ztM=     1   0    NaN   \n",
      "2  D8nEhsIOBSoE6VthTaqDX8U6lqjJ7dLdr72mOyLya2A=     1   0    NaN   \n",
      "3  mCuD+tZ1hERA/o5GPqk38e041J8ZsBaLcu7nGoIIvhI=     1   0    NaN   \n",
      "4  q4HRBfVSssAFS9iRfxWrohxuk9kCYMKjHOEagUMV6rQ=     1   0    NaN   \n",
      "\n",
      "   registered_via  registration_init_time  expiration_date  \n",
      "0               7                20110820         20170920  \n",
      "1               7                20150628         20170622  \n",
      "2               4                20160411         20170712  \n",
      "3               9                20150906         20150907  \n",
      "4               4                20170126         20170613  \n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Information for dataset: test\n",
      "Description\n",
      "                 id\n",
      "count  2.556790e+06\n",
      "mean   1.278394e+06\n",
      "std    7.380818e+05\n",
      "min    0.000000e+00\n",
      "25%    6.391972e+05\n",
      "50%    1.278394e+06\n",
      "75%    1.917592e+06\n",
      "max    2.556789e+06\n",
      "\n",
      "\n",
      "dataframe 'head'\n",
      "   id                                          msno  \\\n",
      "0   0  V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=   \n",
      "1   1  V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=   \n",
      "2   2  /uQAlrAkaczV+nWCd2sPF2ekvXPRipV7q0l+gbLuxjw=   \n",
      "3   3  1a6oo/iXKatxQx4eS9zTVD+KlSVaAFbTIqVvwLC1Y0k=   \n",
      "4   4  1a6oo/iXKatxQx4eS9zTVD+KlSVaAFbTIqVvwLC1Y0k=   \n",
      "\n",
      "                                        song_id source_system_tab  \\\n",
      "0  WmHKgKMlp1lQMecNdNvDMkvIycZYHnFwDT72I5sIssc=        my library   \n",
      "1  y/rsZ9DC7FwK5F2PK2D5mj+aOBUJAjuu3dZ14NgE0vM=        my library   \n",
      "2  8eZLFOdGVdXBSqoAv5nsLigeH2BvKXzTQYtUM53I0k4=          discover   \n",
      "3  ztCf8thYsS4YN3GcIL/bvoxLm/T5mYBVKOO4C9NiVfQ=             radio   \n",
      "4  MKVMpslKcQhMaFEgcEQhEfi5+RZhMYlU3eRDpySrH8Y=             radio   \n",
      "\n",
      "    source_screen_name          source_type  \n",
      "0  Local playlist more        local-library  \n",
      "1  Local playlist more        local-library  \n",
      "2                  NaN  song-based-playlist  \n",
      "3                Radio                radio  \n",
      "4                Radio                radio  \n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Information for dataset: train\n",
      "Description\n",
      "             target\n",
      "count  7.377418e+06\n",
      "mean   5.035171e-01\n",
      "std    4.999877e-01\n",
      "min    0.000000e+00\n",
      "25%    0.000000e+00\n",
      "50%    1.000000e+00\n",
      "75%    1.000000e+00\n",
      "max    1.000000e+00\n",
      "\n",
      "\n",
      "dataframe 'head'\n",
      "                                           msno  \\\n",
      "0  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
      "1  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
      "2  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
      "3  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
      "4  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
      "\n",
      "                                        song_id source_system_tab  \\\n",
      "0  BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=           explore   \n",
      "1  bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=        my library   \n",
      "2  JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=        my library   \n",
      "3  2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=        my library   \n",
      "4  3qm6XTZ6MOCU11x8FIVbAGH5l5uMkT3/ZalWG1oo2Gc=           explore   \n",
      "\n",
      "    source_screen_name      source_type  target  \n",
      "0              Explore  online-playlist       1  \n",
      "1  Local playlist more   local-playlist       1  \n",
      "2  Local playlist more   local-playlist       1  \n",
      "3  Local playlist more   local-playlist       1  \n",
      "4              Explore  online-playlist       1  \n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Information for dataset: songs\n",
      "Description\n",
      "        song_length      language\n",
      "count  2.296320e+06  2.296319e+06\n",
      "mean   2.469935e+05  3.237800e+01\n",
      "std    1.609200e+05  2.433241e+01\n",
      "min    1.850000e+02 -1.000000e+00\n",
      "25%    1.836000e+05 -1.000000e+00\n",
      "50%    2.266270e+05  5.200000e+01\n",
      "75%    2.772690e+05  5.200000e+01\n",
      "max    1.217385e+07  5.900000e+01\n",
      "\n",
      "\n",
      "dataframe 'head'\n",
      "                                        song_id  song_length genre_ids  \\\n",
      "0  CXoTN1eb7AI+DntdU1vbcwGRV4SCIDxZu+YD8JP8r4E=       247640       465   \n",
      "1  o0kFgae9QtnYgRkVPqLJwa05zIhRlUjfF7O1tDw0ZDU=       197328       444   \n",
      "2  DwVvVurfpuz+XPuFvucclVQEyPqcpUkHR0ne1RQzPs0=       231781       465   \n",
      "3  dKMBWoZyScdxSkihKG+Vf47nc18N9q4m58+b4e7dSSE=       273554       465   \n",
      "4  W3bqWd3T+VeHFzHAUfARgW9AvVRaF4N5Yzm4Mr6Eo/o=       140329       726   \n",
      "\n",
      "        artist_name                            composer     lyricist  language  \n",
      "0  張信哲 (Jeff Chang)                                  董貞          何啟弘       3.0  \n",
      "1         BLACKPINK  TEDDY|  FUTURE BOUNCE|  Bekuh BOOM        TEDDY      31.0  \n",
      "2      SUPER JUNIOR                                 NaN          NaN      31.0  \n",
      "3             S.H.E                                 湯小康          徐世珍       3.0  \n",
      "4              貴族精選                         Traditional  Traditional      52.0  \n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Information for dataset: song_extra_info\n",
      "Description\n",
      "                                             song_id     name          isrc\n",
      "count                                        2295971  2295969       2159423\n",
      "unique                                       2295971  1168979       1806825\n",
      "top     S4H2jCFJT45vA42g7by+BU4Ok1icrKe3ekseu9WovNc=    Intro  GBPS81518952\n",
      "freq                                               1     1734           207\n",
      "\n",
      "\n",
      "dataframe 'head'\n",
      "                                        song_id             name          isrc\n",
      "0  LP7pLJoJFBvyuUwvu+oLzjT+bI+UeBPURCecJsX1jjs=               我們  TWUM71200043\n",
      "1  ClazTFnk6r0Bnuie44bocdNMM3rdlrq0bCGAsGUWcHE=  Let Me Love You  QMZSY1600015\n",
      "2  u2ja/bZE3zhCGxvbbOB3zOoUjx27u40cf5g09UXMoKQ=              原諒我  TWA530887303\n",
      "3  92Fqsy0+p6+RHe2EoLKjHahORHR1Kq1TBJoClW9v+Ts=          Classic  USSM11301446\n",
      "4  0QFmz/+rJy1Q56C1DuYqT9hKKqi5TUqx0sN0IwvoHrw=             愛投羅網  TWA471306001\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in datasets.items():\n",
    "    print(f\"Information for dataset: {key}\")\n",
    "    print(\"Description\")\n",
    "    print(value.describe())\n",
    "    print('\\n')\n",
    "    print(\"dataframe 'head'\")\n",
    "    print(value.head())\n",
    "    print('\\n\\n-------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-courage",
   "metadata": {},
   "source": [
    "### In English:\n",
    "- we have a list of users, their personal information, the songs that they liked and didnt like, and where they accesed the song\n",
    "- we also have metadata about each song in the dataset\n",
    "- the dataframe describe function seems to have bugged out with jupyter lab and not shown all of the columns, so I also printed the \"heads\" of each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first task is creating one dataframe that can hold all of our song information robustly\n",
    "# And another which can handle our user data robustly\n",
    "# And pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs583",
   "language": "python",
   "name": "cs583"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
